{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh6qQyH1gui1"
   },
   "source": [
    "# Let's  Deploy fots model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hb1phRktgui6",
    "outputId": "f29e3b23-aacd-4762-a054-1540a43f339a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyngrok==4.1.1 in /usr/local/lib/python3.7/dist-packages (4.1.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (0.16.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyngrok==4.1.1) (3.13)\n",
      "Requirement already satisfied: streamlit in /usr/local/lib/python3.7/dist-packages (0.83.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from streamlit) (20.9)\n",
      "Requirement already satisfied: protobuf!=3.11,>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.12.4)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.1.18)\n",
      "Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (4.1.0)\n",
      "Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (5.1.1)\n",
      "Requirement already satisfied: pandas>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.1.5)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.8.1)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.6.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.19.5)\n",
      "Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.8.1)\n",
      "Requirement already satisfied: validators in /usr/local/lib/python3.7/dist-packages (from streamlit) (0.18.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.23.0)\n",
      "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: watchdog; platform_system != \"Darwin\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.2)\n",
      "Requirement already satisfied: click<8.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from streamlit) (7.1.2)\n",
      "Requirement already satisfied: pyarrow; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from streamlit) (3.0.0)\n",
      "Requirement already satisfied: blinker in /usr/local/lib/python3.7/dist-packages (from streamlit) (1.4)\n",
      "Requirement already satisfied: base58 in /usr/local/lib/python3.7/dist-packages (from streamlit) (2.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->streamlit) (2.4.7)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf!=3.11,>=3.6.0->streamlit) (57.0.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit) (4.0.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.0; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from gitpython->streamlit) (3.7.4.3)\n",
      "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.11.3)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (0.11.1)\n",
      "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from altair>=3.2.0->streamlit) (2.6.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.21.0->streamlit) (2018.9)\n",
      "Requirement already satisfied: ipykernel>=5.1.2; python_version >= \"3.4\" in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.5.5)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pydeck>=0.1.dev5->streamlit) (7.6.3)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators->streamlit) (4.4.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->streamlit) (1.24.3)\n",
      "Requirement already satisfied: smmap<5,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->gitpython->streamlit) (4.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->altair>=3.2.0->streamlit) (2.0.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.3.5)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (5.5.0)\n",
      "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.1.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.5.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.0.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.7.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (22.1.0)\n",
      "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (2.6.1)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (4.8.0)\n",
      "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (1.0.18)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.3.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.0.0->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.6.1)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.10.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.3.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyngrok==4.1.1\n",
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jz6SxnIpSKyi"
   },
   "outputs": [],
   "source": [
    "from pyngrok import ngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sugam95/FOTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVOkmdBxurVR",
    "outputId": "7ec0ddd8-392c-429b-e3f2-005cd05b3c40"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as Patches\n",
    "from shapely.geometry import Polygon\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import threading\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy.optimize\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as Patches\n",
    "from shapely.geometry import Polygon\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import scipy.io as sio\n",
    "try:\n",
    "    import queue\n",
    "except ImportError:\n",
    "    import Queue as queue\n",
    "import streamlit \n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "\n",
    "# This Function is used to calculate AREA of polygon\n",
    "def polygon_area(poly):\n",
    "    '''\n",
    "    compute area of a polygon\n",
    "    '''\n",
    "    edge = [\n",
    "        (poly[1][0] - poly[0][0]) * (poly[1][1] + poly[0][1]),\n",
    "        (poly[2][0] - poly[1][0]) * (poly[2][1] + poly[1][1]),\n",
    "        (poly[3][0] - poly[2][0]) * (poly[3][1] + poly[2][1]),\n",
    "        (poly[0][0] - poly[3][0]) * (poly[0][1] + poly[3][1])\n",
    "    ]\n",
    "    return np.sum(edge)/2.\n",
    "\n",
    "# This function is used to discard invalid polygons and check direction of them\n",
    "\n",
    "def check_and_validate_polys(polys, tags, xxx_todo_changeme):\n",
    "\n",
    "\n",
    "    def is_polygon(poly):\n",
    "        for i in range(3):\n",
    "            p0 = poly[i]\n",
    "\n",
    "        p1 = poly[(i + 1) % 4]\n",
    "        p2 = poly[(i + 2) % 4]\n",
    "    \n",
    "        if p0[0] == p1[0] and p1[1] == p0[1]:\n",
    "            return False\n",
    "        if p0[0] == p2[0] and p2[1] == p0[1]:\n",
    "            return False\n",
    "        if p1[0] == p2[0] and p1[1] == p2[1]:\n",
    "            return False\n",
    "    \n",
    "        if p0[0] == p1[0]:\n",
    "            if p1[0] == p2[0]:\n",
    "                return False\n",
    "        else:\n",
    "            if p1[0] != p2[0]:\n",
    "                k1 = (p1[1] - p0[1]) / (p1[0] - p0[0])\n",
    "                k2 = (p2[1] - p1[1]) / (p2[0] - p1[0])\n",
    "                if abs(k1 - k2) < 1e-6:\n",
    "                    return False\n",
    "                else:\n",
    "                    if p1[1] == p2[1]:\n",
    "                        return False\n",
    "        \n",
    "        return True\n",
    "\n",
    "    (h, w) = xxx_todo_changeme\n",
    "    if polys.shape[0] == 0:\n",
    "        return polys\n",
    "    polys[:, :, 0] = np.clip(polys[:, :, 0], 0, w - 1)\n",
    "    polys[:, :, 1] = np.clip(polys[:, :, 1], 0, h - 1)\n",
    "\n",
    "    validated_polys = []\n",
    "    validated_tags = []\n",
    "    for poly, tag in zip(polys, tags):\n",
    "        p_area = polygon_area(poly)\n",
    "\n",
    "        # memory error after hitting not a polygon !!!\n",
    "        if is_polygon(poly) is False:\n",
    "            #print(\"not a polygon: \", poly)\n",
    "            continue\n",
    "\n",
    "        if abs(p_area) < 1:\n",
    "            # print poly\n",
    "            #print('invalid poly')\n",
    "            continue\n",
    "        if p_area > 0:\n",
    "            #print('poly in wrong direction')\n",
    "            poly = poly[(0, 3, 2, 1), :]\n",
    "        validated_polys.append(poly)\n",
    "        validated_tags.append(tag)\n",
    "    return np.array(validated_polys), np.array(validated_tags)    \n",
    "    \n",
    "    \n",
    "#This function is implementation of Polygon Shrinkage Algorithm \n",
    "def shrink_poly(poly, r):\n",
    "    '''\n",
    "    fit a poly inside the origin poly\n",
    "    used for generate the score map\n",
    "    '''\n",
    "    # shrink ratio\n",
    "    ratio = 0.3\n",
    "    # find the longer pair\n",
    "    if np.linalg.norm(poly[0] - poly[1]) + np.linalg.norm(poly[2] - poly[3]) > \\\n",
    "                    np.linalg.norm(poly[0] - poly[3]) + np.linalg.norm(poly[1] - poly[2]):\n",
    "        # first move (p0, p1), (p2, p3), then (p0, p3), (p1, p2)\n",
    "        ## p0, p1\n",
    "        theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n",
    "        poly[0][0] += ratio * r[0] * np.cos(theta)\n",
    "        poly[0][1] += ratio * r[0] * np.sin(theta)\n",
    "        poly[1][0] -= ratio * r[1] * np.cos(theta)\n",
    "        poly[1][1] -= ratio * r[1] * np.sin(theta)\n",
    "        ## p2, p3\n",
    "        theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n",
    "        poly[3][0] += ratio * r[3] * np.cos(theta)\n",
    "        poly[3][1] += ratio * r[3] * np.sin(theta)\n",
    "        poly[2][0] -= ratio * r[2] * np.cos(theta)\n",
    "        poly[2][1] -= ratio * r[2] * np.sin(theta)\n",
    "        ## p0, p3\n",
    "        theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n",
    "        poly[0][0] += ratio * r[0] * np.sin(theta)\n",
    "        poly[0][1] += ratio * r[0] * np.cos(theta)\n",
    "        poly[3][0] -= ratio * r[3] * np.sin(theta)\n",
    "        poly[3][1] -= ratio * r[3] * np.cos(theta)\n",
    "        ## p1, p2\n",
    "        theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n",
    "        poly[1][0] += ratio * r[1] * np.sin(theta)\n",
    "        poly[1][1] += ratio * r[1] * np.cos(theta)\n",
    "        poly[2][0] -= ratio * r[2] * np.sin(theta)\n",
    "        poly[2][1] -= ratio * r[2] * np.cos(theta)\n",
    "    else:\n",
    "        ## p0, p3\n",
    "        # print poly\n",
    "        theta = np.arctan2((poly[3][0] - poly[0][0]), (poly[3][1] - poly[0][1]))\n",
    "        poly[0][0] += ratio * r[0] * np.sin(theta)\n",
    "        poly[0][1] += ratio * r[0] * np.cos(theta)\n",
    "        poly[3][0] -= ratio * r[3] * np.sin(theta)\n",
    "        poly[3][1] -= ratio * r[3] * np.cos(theta)\n",
    "        ## p1, p2\n",
    "        theta = np.arctan2((poly[2][0] - poly[1][0]), (poly[2][1] - poly[1][1]))\n",
    "        poly[1][0] += ratio * r[1] * np.sin(theta)\n",
    "        poly[1][1] += ratio * r[1] * np.cos(theta)\n",
    "        poly[2][0] -= ratio * r[2] * np.sin(theta)\n",
    "        poly[2][1] -= ratio * r[2] * np.cos(theta)\n",
    "        ## p0, p1\n",
    "        theta = np.arctan2((poly[1][1] - poly[0][1]), (poly[1][0] - poly[0][0]))\n",
    "        poly[0][0] += ratio * r[0] * np.cos(theta)\n",
    "        poly[0][1] += ratio * r[0] * np.sin(theta)\n",
    "        poly[1][0] -= ratio * r[1] * np.cos(theta)\n",
    "        poly[1][1] -= ratio * r[1] * np.sin(theta)\n",
    "        ## p2, p3\n",
    "        theta = np.arctan2((poly[2][1] - poly[3][1]), (poly[2][0] - poly[3][0]))\n",
    "        poly[3][0] += ratio * r[3] * np.cos(theta)\n",
    "        poly[3][1] += ratio * r[3] * np.sin(theta)\n",
    "        poly[2][0] -= ratio * r[2] * np.cos(theta)\n",
    "        poly[2][1] -= ratio * r[2] * np.sin(theta)\n",
    "    return poly\n",
    "\n",
    "\n",
    "\n",
    "#Compute distance between p1-p2 and p3\n",
    "def point_dist_to_line(p1, p2, p3):\n",
    "    '''compute the distance from p3 to p1-p2'''\n",
    "    return np.linalg.norm(np.cross(p2 - p1, p1 - p3)) / np.linalg.norm(p2 - p1)\n",
    "\n",
    "#Find equation of line using two 2D points p1 and p2\n",
    "def fit_line(p1, p2):\n",
    "    '''fit a line ax+by+c = 0'''\n",
    "    if p1[0] == p1[1]:\n",
    "        return [1., 0., -p1[0]]\n",
    "    else:\n",
    "        [k, b] = np.polyfit(p1, p2, deg=1)\n",
    "        return [k, -1., b]\n",
    "\n",
    "#Find Intersection poitn of 2 lines\n",
    "def line_cross_point(line1, line2):\n",
    "    '''line1 0= ax+by+c, compute the cross point of line1 and line2'''\n",
    "    if line1[0] != 0 and line1[0] == line2[0]:\n",
    "        print('Cross point does not exist')\n",
    "        return None\n",
    "    if line1[0] == 0 and line2[0] == 0:\n",
    "        print('Cross point does not exist')\n",
    "        return None\n",
    "    if line1[1] == 0:\n",
    "        x = -line1[2]\n",
    "        y = line2[0] * x + line2[2]\n",
    "    elif line2[1] == 0:\n",
    "        x = -line2[2]\n",
    "        y = line1[0] * x + line1[2]\n",
    "    else:\n",
    "        k1, _, b1 = line1\n",
    "        k2, _, b2 = line2\n",
    "        x = -(b1-b2)/(k1-k2)\n",
    "        y = k1*x + b1\n",
    "    return np.array([x, y], dtype=np.float32)\n",
    "\n",
    "#Get Equation of line that is perpendicular to line passing through a point\n",
    "def line_verticle(line, point):\n",
    "    '''get the verticle line from line across point'''\n",
    "    if line[1] == 0:\n",
    "        verticle = [0, -1, point[1]]\n",
    "    else:\n",
    "        if line[0] == 0:\n",
    "            verticle = [1, 0, -point[0]]\n",
    "        else:\n",
    "            verticle = [-1./line[0], -1, point[1] - (-1/line[0] * point[0])]\n",
    "    return verticle\n",
    "\n",
    "# Convert a parallelogram to rectangle\n",
    "def rectangle_from_parallelogram(poly):\n",
    "    '''\n",
    "    fit a rectangle from a parallelogram\n",
    "    '''\n",
    "    p0, p1, p2, p3 = poly\n",
    "    angle_p0 = np.arccos(np.dot(p1-p0, p3-p0)/(np.linalg.norm(p0-p1) * np.linalg.norm(p3-p0)))\n",
    "    if angle_p0 < 0.5 * np.pi:\n",
    "        if np.linalg.norm(p0 - p1) > np.linalg.norm(p0-p3):\n",
    "            # p0 and p2\n",
    "            ## p0\n",
    "            p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n",
    "            p2p3_verticle = line_verticle(p2p3, p0)\n",
    "\n",
    "            new_p3 = line_cross_point(p2p3, p2p3_verticle)\n",
    "            ## p2\n",
    "            p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
    "            p0p1_verticle = line_verticle(p0p1, p2)\n",
    "\n",
    "            new_p1 = line_cross_point(p0p1, p0p1_verticle)\n",
    "            return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n",
    "        else:\n",
    "            p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
    "            p1p2_verticle = line_verticle(p1p2, p0)\n",
    "\n",
    "            new_p1 = line_cross_point(p1p2, p1p2_verticle)\n",
    "            p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
    "            p0p3_verticle = line_verticle(p0p3, p2)\n",
    "\n",
    "            new_p3 = line_cross_point(p0p3, p0p3_verticle)\n",
    "            return np.array([p0, new_p1, p2, new_p3], dtype=np.float32)\n",
    "    else:\n",
    "        if np.linalg.norm(p0-p1) > np.linalg.norm(p0-p3):\n",
    "            # p1 and p3\n",
    "            ## p1\n",
    "            p2p3 = fit_line([p2[0], p3[0]], [p2[1], p3[1]])\n",
    "            p2p3_verticle = line_verticle(p2p3, p1)\n",
    "\n",
    "            new_p2 = line_cross_point(p2p3, p2p3_verticle)\n",
    "            ## p3\n",
    "            p0p1 = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
    "            p0p1_verticle = line_verticle(p0p1, p3)\n",
    "\n",
    "            new_p0 = line_cross_point(p0p1, p0p1_verticle)\n",
    "            return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n",
    "        else:\n",
    "            p0p3 = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
    "            p0p3_verticle = line_verticle(p0p3, p1)\n",
    "\n",
    "            new_p0 = line_cross_point(p0p3, p0p3_verticle)\n",
    "            p1p2 = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
    "            p1p2_verticle = line_verticle(p1p2, p3)\n",
    "\n",
    "            new_p2 = line_cross_point(p1p2, p1p2_verticle)\n",
    "            return np.array([new_p0, p1, new_p2, p3], dtype=np.float32)\n",
    "\n",
    "#Sorting a rectangle to get all point in clockwies manner\n",
    "def sort_rectangle(poly):\n",
    "    '''sort the four coordinates of the polygon, points in poly should be sorted clockwise'''\n",
    "    # First find the lowest point\n",
    "    p_lowest = np.argmax(poly[:, 1])\n",
    "    if np.count_nonzero(poly[:, 1] == poly[p_lowest, 1]) == 2:\n",
    "        # if the bottom line is parallel to x-axis, then p0 must be the upper-left corner\n",
    "        p0_index = np.argmin(np.sum(poly, axis=1))\n",
    "        p1_index = (p0_index + 1) % 4\n",
    "        p2_index = (p0_index + 2) % 4\n",
    "        p3_index = (p0_index + 3) % 4\n",
    "        return poly[[p0_index, p1_index, p2_index, p3_index]], 0.\n",
    "    else:\n",
    "        # find the point that sits right to the lowest point\n",
    "        p_lowest_right = (p_lowest - 1) % 4\n",
    "        p_lowest_left = (p_lowest + 1) % 4\n",
    "        angle = np.arctan(-(poly[p_lowest][1] - poly[p_lowest_right][1])/(poly[p_lowest][0] - poly[p_lowest_right][0]))\n",
    "        # assert angle > 0\n",
    "        if angle <= 0:\n",
    "            print(angle, poly[p_lowest], poly[p_lowest_right])\n",
    "        if angle/np.pi * 180 > 45:\n",
    "            #this point is p2\n",
    "            p2_index = p_lowest\n",
    "            p1_index = (p2_index - 1) % 4\n",
    "            p0_index = (p2_index - 2) % 4\n",
    "            p3_index = (p2_index + 1) % 4\n",
    "            return poly[[p0_index, p1_index, p2_index, p3_index]], -(np.pi/2 - angle)\n",
    "        else:\n",
    "            # this point is p3\n",
    "            p3_index = p_lowest\n",
    "            p0_index = (p3_index + 1) % 4\n",
    "            p1_index = (p3_index + 2) % 4\n",
    "            p2_index = (p3_index + 3) % 4\n",
    "            return poly[[p0_index, p1_index, p2_index, p3_index]], angle\n",
    "\n",
    "\n",
    "def restore_rectangle_rbox(origin, geometry):\n",
    "    ''' Resotre rectangle tbox'''\n",
    "    d = geometry[:, :4]\n",
    "    angle = geometry[:, 4]\n",
    "    # for angle > 0\n",
    "    origin_0 = origin[angle >= 0]\n",
    "    d_0 = d[angle >= 0]\n",
    "    angle_0 = angle[angle >= 0]\n",
    "    if origin_0.shape[0] > 0:\n",
    "        p = np.array([np.zeros(d_0.shape[0]), -d_0[:, 0] - d_0[:, 2],\n",
    "                      d_0[:, 1] + d_0[:, 3], -d_0[:, 0] - d_0[:, 2],\n",
    "                      d_0[:, 1] + d_0[:, 3], np.zeros(d_0.shape[0]),\n",
    "                      np.zeros(d_0.shape[0]), np.zeros(d_0.shape[0]),\n",
    "                      d_0[:, 3], -d_0[:, 2]])\n",
    "        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
    "\n",
    "        rotate_matrix_x = np.array([np.cos(angle_0), np.sin(angle_0)]).transpose((1, 0))\n",
    "        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
    "\n",
    "        rotate_matrix_y = np.array([-np.sin(angle_0), np.cos(angle_0)]).transpose((1, 0))\n",
    "        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
    "\n",
    "        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "\n",
    "        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
    "\n",
    "        p3_in_origin = origin_0 - p_rotate[:, 4, :]\n",
    "        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
    "        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
    "        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
    "        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
    "\n",
    "        new_p_0 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
    "                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
    "    else:\n",
    "        new_p_0 = np.zeros((0, 4, 2))\n",
    "    # for angle < 0\n",
    "    origin_1 = origin[angle < 0]\n",
    "    d_1 = d[angle < 0]\n",
    "    angle_1 = angle[angle < 0]\n",
    "    if origin_1.shape[0] > 0:\n",
    "        p = np.array([-d_1[:, 1] - d_1[:, 3], -d_1[:, 0] - d_1[:, 2],\n",
    "                      np.zeros(d_1.shape[0]), -d_1[:, 0] - d_1[:, 2],\n",
    "                      np.zeros(d_1.shape[0]), np.zeros(d_1.shape[0]),\n",
    "                      -d_1[:, 1] - d_1[:, 3], np.zeros(d_1.shape[0]),\n",
    "                      -d_1[:, 1], -d_1[:, 2]])\n",
    "        p = p.transpose((1, 0)).reshape((-1, 5, 2))  # N*5*2\n",
    "\n",
    "        rotate_matrix_x = np.array([np.cos(-angle_1), -np.sin(-angle_1)]).transpose((1, 0))\n",
    "        rotate_matrix_x = np.repeat(rotate_matrix_x, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))  # N*5*2\n",
    "\n",
    "        rotate_matrix_y = np.array([np.sin(-angle_1), np.cos(-angle_1)]).transpose((1, 0))\n",
    "        rotate_matrix_y = np.repeat(rotate_matrix_y, 5, axis=1).reshape(-1, 2, 5).transpose((0, 2, 1))\n",
    "\n",
    "        p_rotate_x = np.sum(rotate_matrix_x * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "        p_rotate_y = np.sum(rotate_matrix_y * p, axis=2)[:, :, np.newaxis]  # N*5*1\n",
    "\n",
    "        p_rotate = np.concatenate([p_rotate_x, p_rotate_y], axis=2)  # N*5*2\n",
    "\n",
    "        p3_in_origin = origin_1 - p_rotate[:, 4, :]\n",
    "        new_p0 = p_rotate[:, 0, :] + p3_in_origin  # N*2\n",
    "        new_p1 = p_rotate[:, 1, :] + p3_in_origin\n",
    "        new_p2 = p_rotate[:, 2, :] + p3_in_origin\n",
    "        new_p3 = p_rotate[:, 3, :] + p3_in_origin\n",
    "\n",
    "        new_p_1 = np.concatenate([new_p0[:, np.newaxis, :], new_p1[:, np.newaxis, :],\n",
    "                                  new_p2[:, np.newaxis, :], new_p3[:, np.newaxis, :]], axis=1)  # N*4*2\n",
    "    else:\n",
    "        new_p_1 = np.zeros((0, 4, 2))\n",
    "    return np.concatenate([new_p_0, new_p_1])\n",
    "\n",
    "\n",
    "#Some geometrical functions used in codes\n",
    "def restore_rectangle(origin, geometry):\n",
    "    return restore_rectangle_rbox(origin, geometry)\n",
    "\n",
    "def getRotateRect(box):\n",
    "    rect = cv2.minAreaRect(box)\n",
    "\n",
    "    angle=rect[2]  # angle = [-90, 0)\n",
    "    if angle < -45:\n",
    "        rect = (rect[0], (rect[1][0], rect[1][1]), rect[2])\n",
    "        angle += 90\n",
    "        size = (rect[1][1],rect[1][0])\n",
    "    else:\n",
    "        rect = (rect[0], (rect[1][0], rect[1][1]), rect[2])\n",
    "        size=rect[1]\n",
    "\n",
    "    box_ = cv2.boxPoints(rect)\n",
    "    return np.concatenate([rect[0], size]), angle, box_\n",
    "\n",
    "\n",
    "#These Functions are used to Generate ROI params like out box,crop box & angles that we use to crop text from image\n",
    "def generate_roiRotatePara(box, angle, expand_w = 60):\n",
    "    '''Generate all ROI Parameterts'''\n",
    "    p0_rect, p1_rect, p2_rect, p3_rect = box\n",
    "    cxy = (p0_rect + p2_rect) / 2.\n",
    "    size = np.array([np.linalg.norm(p0_rect - p1_rect), np.linalg.norm(p0_rect - p3_rect)])\n",
    "    rrect = np.concatenate([cxy, size])\n",
    "\n",
    "    box=np.array(box)\n",
    "\n",
    "    points=np.array(box, dtype=np.int32)\n",
    "    xmin=np.min(points[:,0])\n",
    "    xmax=np.max(points[:,0])\n",
    "    ymin=np.min(points[:,1])\n",
    "    ymax=np.max(points[:,1])\n",
    "    bbox = np.array([xmin, ymin, xmax, ymax])\n",
    "    if np.any(bbox < -expand_w):\n",
    "        return None\n",
    "    \n",
    "    rrect[:2] -= bbox[:2]\n",
    "    rrect[:2] -= rrect[2:] / 2\n",
    "    rrect[2:] += rrect[:2]\n",
    "\n",
    "    bbox[2:] -= bbox[:2]\n",
    "\n",
    "    rrect[::2] = np.clip(rrect[::2], 0, bbox[2])\n",
    "    rrect[1::2] = np.clip(rrect[1::2], 0, bbox[3])\n",
    "    rrect[2:] -= rrect[:2]\n",
    "    \n",
    "    return bbox.astype(np.int32), rrect.astype(np.int32), - angle\n",
    "\n",
    "def restore_roiRotatePara(box):\n",
    "    rectange, rotate_angle = sort_rectangle(box)\n",
    "    return generate_roiRotatePara(rectange, rotate_angle)\n",
    "\n",
    "#This function is used to generate geo_map,score_map, training_mask,corp_box,out_box,angle that we use while training model\n",
    "def generate_rbox(im_size, polys, tags):\n",
    "    '''Genrate score_map and geo_map for image'''\n",
    "    h, w = im_size\n",
    "    poly_mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    score_map = np.zeros((h, w), dtype=np.uint8)\n",
    "    geo_map = np.zeros((h, w, 5), dtype=np.float32)\n",
    "\n",
    "    outBoxs = []\n",
    "    cropBoxs = []\n",
    "    angles = []\n",
    "    text_tags = []\n",
    "    recg_masks = []\n",
    "    # mask used during traning, to ignore some hard areas\n",
    "    training_mask = np.ones((h, w), dtype=np.uint8)\n",
    "    for poly_idx, poly_tag in enumerate(zip(polys, tags)):\n",
    "        poly = poly_tag[0]\n",
    "        #print(poly)\n",
    "        tag = poly_tag[1]\n",
    "        #print(tag)\n",
    "        r = [None, None, None, None]\n",
    "        for i in range(4):\n",
    "            r[i] = min(np.linalg.norm(poly[i] - poly[(i + 1) % 4]),\n",
    "                       np.linalg.norm(poly[i] - poly[(i - 1) % 4]))\n",
    "        # score map\n",
    "        shrinked_poly = shrink_poly(poly.copy(), r).astype(np.int32)[np.newaxis, :, :]\n",
    "        cv2.fillPoly(score_map, shrinked_poly, 1)\n",
    "        cv2.fillPoly(poly_mask, shrinked_poly, poly_idx + 1)\n",
    "\n",
    "        # if geometry == 'RBOX':\n",
    "        # generate a parallelogram for any combination of two vertices\n",
    "        fitted_parallelograms = []\n",
    "        for i in range(4):\n",
    "            p0 = poly[i]\n",
    "            p1 = poly[(i + 1) % 4]\n",
    "            p2 = poly[(i + 2) % 4]\n",
    "            p3 = poly[(i + 3) % 4]\n",
    "            edge = fit_line([p0[0], p1[0]], [p0[1], p1[1]])\n",
    "            backward_edge = fit_line([p0[0], p3[0]], [p0[1], p3[1]])\n",
    "            forward_edge = fit_line([p1[0], p2[0]], [p1[1], p2[1]])\n",
    "            if point_dist_to_line(p0, p1, p2) > point_dist_to_line(p0, p1, p3):\n",
    "                #  parallel lines through p2\n",
    "                if edge[1] == 0:\n",
    "                    edge_opposite = [1, 0, -p2[0]]\n",
    "                else:\n",
    "                    edge_opposite = [edge[0], -1, p2[1] - edge[0] * p2[0]]\n",
    "            else:\n",
    "                # after p3\n",
    "                if edge[1] == 0:\n",
    "                    edge_opposite = [1, 0, -p3[0]]\n",
    "                else:\n",
    "                    edge_opposite = [edge[0], -1, p3[1] - edge[0] * p3[0]]\n",
    "            # move forward edge\n",
    "            new_p0 = p0\n",
    "            new_p1 = p1\n",
    "            new_p2 = p2\n",
    "            new_p3 = p3\n",
    "            new_p2 = line_cross_point(forward_edge, edge_opposite)\n",
    "            if point_dist_to_line(p1, new_p2, p0) > point_dist_to_line(p1, new_p2, p3):\n",
    "                # across p0\n",
    "                if forward_edge[1] == 0:\n",
    "                    forward_opposite = [1, 0, -p0[0]]\n",
    "                else:\n",
    "                    forward_opposite = [forward_edge[0], -1, p0[1] - forward_edge[0] * p0[0]]\n",
    "            else:\n",
    "                # across p3\n",
    "                if forward_edge[1] == 0:\n",
    "                    forward_opposite = [1, 0, -p3[0]]\n",
    "                else:\n",
    "                    forward_opposite = [forward_edge[0], -1, p3[1] - forward_edge[0] * p3[0]]\n",
    "            new_p0 = line_cross_point(forward_opposite, edge)\n",
    "            new_p3 = line_cross_point(forward_opposite, edge_opposite)\n",
    "            fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n",
    "            # or move backward edge\n",
    "            new_p0 = p0\n",
    "            new_p1 = p1\n",
    "            new_p2 = p2\n",
    "            new_p3 = p3\n",
    "            new_p3 = line_cross_point(backward_edge, edge_opposite)\n",
    "            if point_dist_to_line(p0, p3, p1) > point_dist_to_line(p0, p3, p2):\n",
    "                # across p1\n",
    "                if backward_edge[1] == 0:\n",
    "                    backward_opposite = [1, 0, -p1[0]]\n",
    "                else:\n",
    "                    backward_opposite = [backward_edge[0], -1, p1[1] - backward_edge[0] * p1[0]]\n",
    "            else:\n",
    "                # across p2\n",
    "                if backward_edge[1] == 0:\n",
    "                    backward_opposite = [1, 0, -p2[0]]\n",
    "                else:\n",
    "                    backward_opposite = [backward_edge[0], -1, p2[1] - backward_edge[0] * p2[0]]\n",
    "            new_p1 = line_cross_point(backward_opposite, edge)\n",
    "            new_p2 = line_cross_point(backward_opposite, edge_opposite)\n",
    "            fitted_parallelograms.append([new_p0, new_p1, new_p2, new_p3, new_p0])\n",
    "        areas = [Polygon(t).area for t in fitted_parallelograms]\n",
    "        parallelogram = np.array(fitted_parallelograms[np.argmin(areas)][:-1], dtype=np.float32)\n",
    "        # sort thie polygon\n",
    "        parallelogram_coord_sum = np.sum(parallelogram, axis=1)\n",
    "        min_coord_idx = np.argmin(parallelogram_coord_sum)\n",
    "        parallelogram = parallelogram[\n",
    "            [min_coord_idx, (min_coord_idx + 1) % 4, (min_coord_idx + 2) % 4, (min_coord_idx + 3) % 4]]\n",
    "\n",
    "        rectange = rectangle_from_parallelogram(parallelogram)\n",
    "        rectange, rotate_angle = sort_rectangle(rectange)\n",
    "\n",
    "        p0_rect, p1_rect, p2_rect, p3_rect = rectange\n",
    "\n",
    "        # if the poly is too small, then ignore it during training\n",
    "        poly_h = min(np.linalg.norm(p0_rect - p3_rect), np.linalg.norm(p1_rect - p2_rect))\n",
    "        poly_w = min(np.linalg.norm(p0_rect - p1_rect), np.linalg.norm(p2_rect - p3_rect))\n",
    "\n",
    "        invaild = (min(poly_h, poly_w) < 6) or tag is None or (True and poly_h > poly_w * 2)\n",
    "\n",
    "        if invaild:\n",
    "            cv2.fillPoly(training_mask, poly.astype(np.int32)[np.newaxis, :, :], 0)\n",
    "        xy_in_poly = np.argwhere(poly_mask == (poly_idx + 1))\n",
    "        \n",
    "        if not invaild:\n",
    "            roiRotatePara = generate_roiRotatePara(rectange, rotate_angle)\n",
    "            if roiRotatePara:\n",
    "                outBox, cropBox, angle = roiRotatePara\n",
    "                if min(cropBox[2:]) > 6:\n",
    "                    w , h = cropBox[2:]\n",
    "                    textImgW = np.ceil(min(w / float(h) * 32, 256) / 4 /1)\n",
    "                    #print(tag)\n",
    "                    if textImgW >= 2 * min(len(tag), 16):  # avoid CTC error\n",
    "                        outBoxs.append(outBox)\n",
    "                        cropBoxs.append(cropBox)\n",
    "                        angles.append(angle)\n",
    "                        text_tags.append(tag[:16])\n",
    "                        recg_masks.append(1.)\n",
    "\n",
    "        for y, x in xy_in_poly:\n",
    "            point = np.array([x, y], dtype=np.float32)\n",
    "            # top\n",
    "            geo_map[y, x, 0] = point_dist_to_line(p0_rect, p1_rect, point) + 3\n",
    "            # right\n",
    "            geo_map[y, x, 1] = point_dist_to_line(p1_rect, p2_rect, point) + 3\n",
    "            # down\n",
    "            geo_map[y, x, 2] = point_dist_to_line(p2_rect, p3_rect, point) + 3\n",
    "            # left\n",
    "            geo_map[y, x, 3] = point_dist_to_line(p3_rect, p0_rect, point) + 3\n",
    "            # angle\n",
    "            geo_map[y, x, 4] = rotate_angle\n",
    "    if len(outBoxs) == 0:\n",
    "        outBoxs.append([0, 0, 2 * 4, 2 * 4]) # keep extract From sharedConv feature map not zero\n",
    "        cropBoxs.append([0, 0, 2 * 4, 2 * 4])\n",
    "        angles.append(0.)\n",
    "        text_tags.append([NUM_CLASSES - 2])\n",
    "        recg_masks.append(0.)\n",
    "\n",
    "    outBoxs = np.array(outBoxs, np.int32)\n",
    "    cropBoxs = np.array(cropBoxs, np.int32)\n",
    "    angles = np.array(angles, np.float32)\n",
    "\n",
    "    return score_map, geo_map, training_mask, (outBoxs, cropBoxs, angles), text_tags, recg_masks\n",
    "    \n",
    "\n",
    "\n",
    "#These Are Function that will be used while converting geo_maps to score_maps and returns bounding boxes for image after nms\n",
    "\n",
    "def sort_poly(p):\n",
    "  min_axis = np.argmin(np.sum(p, axis=1))\n",
    "  p = p[[min_axis, (min_axis+1)%4, (min_axis+2)%4, (min_axis+3)%4]]\n",
    "  if abs(p[0, 0] - p[1, 0]) > abs(p[0, 1] - p[1, 1]):\n",
    "    return p\n",
    "  else:\n",
    "    return p[[0, 3, 2, 1]]\n",
    "def intersection(g, p):\n",
    "    g = Polygon(g[:8].reshape((4, 2)))\n",
    "    p = Polygon(p[:8].reshape((4, 2)))\n",
    "    if not g.is_valid or not p.is_valid:\n",
    "        return 0\n",
    "    inter = Polygon(g).intersection(Polygon(p)).area\n",
    "    union = g.area + p.area - inter\n",
    "    if union == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return inter/union\n",
    "\n",
    "\n",
    "def weighted_merge(g, p):\n",
    "    g[:8] = (g[8] * g[:8] + p[8] * p[:8])/(g[8] + p[8])\n",
    "    g[8] = (g[8] + p[8])\n",
    "    return g\n",
    "\n",
    "\n",
    "def standard_nms(S, thres):\n",
    "    order = np.argsort(S[:, 8])[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        ovr = np.array([intersection(S[i], S[t]) for t in order[1:]])\n",
    "\n",
    "        inds = np.where(ovr <= thres)[0]\n",
    "        order = order[inds+1]\n",
    "\n",
    "    return S[keep]\n",
    "\n",
    "\n",
    "def nms_locality(polys, thres=0.3):\n",
    "    '''\n",
    "    :param polys: a N*9 numpy array. first 8 coordinates, then prob\n",
    "    :return: boxes after nms\n",
    "    '''\n",
    "    S = []\n",
    "    p = None\n",
    "  \n",
    "    for g in polys:\n",
    "        if p is not None and intersection(g, p) > thres:\n",
    "        \n",
    "            p = weighted_merge(g, p)\n",
    "        else:\n",
    "            if p is not None:\n",
    "                S.append(p)\n",
    "            p = g\n",
    "  \n",
    "    if p is not None:\n",
    "        S.append(p)\n",
    "\n",
    "    if len(S) == 0:\n",
    "        return np.array([])\n",
    "    \n",
    "    return standard_nms(np.array(S), thres)\n",
    "\n",
    "\n",
    "#This is final Inference function used for complete FOTS pipeline\n",
    "def Final_Model(img):\n",
    "  '''This function is main complete pipeline of our Model'''\n",
    "  start_time=time.time()\n",
    "  \n",
    "  #1.Text Detection\n",
    "  img=cv2.resize(img,(512,512))\n",
    "  ii=detection_model.predict(np.expand_dims(img,axis=0))\n",
    "  score_map=ii[0][:,:,0]\n",
    "  geo_map=ii[0][:,:,1:]\n",
    "\n",
    "\n",
    "  for ind in [0,1,2,3,4]:\n",
    "    geo_map[:,:,ind]*=score_map\n",
    "\n",
    "\n",
    "  #2.ROI Rotate  \n",
    "  score_map_thresh=0.5\n",
    "  box_thresh=0.1 \n",
    "  nms_thres=0.2\n",
    "  if len(score_map.shape) == 4:\n",
    "    score_map = score_map[0, :, :, 0]\n",
    "    geo_map = geo_map[0, :, :, :]\n",
    "  # filter the score map\n",
    "  xy_text = np.argwhere(score_map > score_map_thresh)\n",
    "  # sort the text boxes via the y axis\n",
    "  xy_text = xy_text[np.argsort(xy_text[:, 0])]\n",
    "  # restore\n",
    "  text_box_restored = restore_rectangle(xy_text[:, ::-1], geo_map[xy_text[:, 0], xy_text[:, 1], :]) # N*4*2\n",
    "  boxes = np.zeros((text_box_restored.shape[0], 9), dtype=np.float32)\n",
    "  boxes[:, :8] = text_box_restored.reshape((-1, 8))\n",
    "  boxes[:, 8] = score_map[xy_text[:, 0], xy_text[:, 1]]\n",
    "  boxes = nms_locality(boxes.astype(np.float64), nms_thres)\n",
    "\n",
    "  # here we filter some low score boxes by the average score map, this is different from the orginal paper\n",
    "  for i, box in enumerate(boxes):\n",
    "    mask = np.zeros_like(score_map, dtype=np.uint8)\n",
    "    cv2.fillPoly(mask, box[:8].reshape((-1, 4, 2)).astype(np.int32), 1)\n",
    "    boxes[i, 8] = cv2.mean(score_map, mask)[0]\n",
    "    if i==4:\n",
    "      break\n",
    "  if len(boxes)>0:\n",
    "    boxes = boxes[boxes[:, 8] > box_thresh]\n",
    "  boxes[:,:8:2] = np.clip(boxes[:,:8:2], 0, 512 - 1)\n",
    "  boxes[:,1:8:2] = np.clip(boxes[:,1:8:2], 0, 512 - 1)  \n",
    "  res = []\n",
    "  result = []\n",
    "  if len(boxes)>0:\n",
    "    for box in boxes:\n",
    "      box_ =  box[:8].reshape((4, 2))\n",
    "      if np.linalg.norm(box_[0] - box_[1]) < 8 or np.linalg.norm(box_[3]-box_[0]) < 8:\n",
    "        continue\n",
    "      result.append(box_)\n",
    "  res.append(np.array(result, np.float32))   \n",
    "\n",
    "  box_index = []\n",
    "  brotateParas = []\n",
    "  filter_bsharedFeatures = []\n",
    "  for i in range(len(res)):\n",
    "    rotateParas = []\n",
    "    rboxes=res[i]\n",
    "    txt=[]\n",
    "    for j, rbox in enumerate(rboxes):\n",
    "      para = restore_roiRotatePara(rbox)\n",
    "      if para and min(para[1][2:]) > 8:\n",
    "        rotateParas.append(para)\n",
    "        box_index.append((i, j))\n",
    "    pts=[]   \n",
    "    \n",
    "    \n",
    "    #3. Text Recognition (From boxes given by Text Detection+ROI Rotate) \n",
    "    \n",
    "    if len(rotateParas) > 0:\n",
    "      for num in range(len(rotateParas)):\n",
    "        text=\"\"\n",
    "        out=rotateParas[num][0]\n",
    "        crop=rotateParas[num][1]\n",
    "        points=np.array([[out[0],out[1]],[out[0]+out[2],out[1]],[out[0]+out[2],out[1]+out[3]],[out[0],out[1]+out[3]]])\n",
    "        angle=rotateParas[num][2] \n",
    "        img1=tf.image.crop_to_bounding_box(img,out[1],out[0],out[3],out[2])\n",
    "        img2=tf.keras.preprocessing.image.random_rotation(img1,angle)\n",
    "        img2=tf.image.crop_to_bounding_box(img2,crop[1],crop[0],crop[3],crop[2]).numpy()\n",
    "        img2=cv2.resize(img2,(128,64))\n",
    "        img2=cv2.detailEnhance(img2)\n",
    "        ii=recogniion_model.predict(np.expand_dims(img2,axis=0))\n",
    "        arr=tf.keras.backend.ctc_decode(ii,np.ones((1),'int8')*64,)\n",
    "        for val in arr[0][0].numpy()[0]:\n",
    "          if val==-1:\n",
    "            break\n",
    "          else:\n",
    "            text+=index_char[val]\n",
    "        txt.append(text)\n",
    "        pts.append(points)\n",
    "    \n",
    "    # 4. Labeling detected and Recognized Text in Image\n",
    "    \n",
    "    for i in range(len(txt)):\n",
    "      cv2.polylines(img,[pts[i]],isClosed=True,color=(0,255,0),thickness=1)\n",
    "      cv2.putText(img,txt[i],(pts[i][0][0],pts[i][0][1]),cv2.FONT_HERSHEY_SIMPLEX,1, (255,0,0), 2)\n",
    "    end_time=time.time()\n",
    "    print(\"Time Taken By Pipeline=\"+str(end_time-start_time)+\" seconds\")  \n",
    "    return img,txt    \n",
    "\n",
    "\n",
    "@streamlit.cache(show_spinner=False)\n",
    "def detection():\n",
    "    # Creating a deconv layer which used in text detection branch\n",
    "    class Deconv_layer(tf.keras.layers.Layer):\n",
    "      def __init__(self,name=\"deconv\"):\n",
    "          super().__init__(name)\n",
    "          self.inp_size=0\n",
    "          self.conv_layer=None\n",
    "          self.upsample_layer=None\n",
    "          self.btach_norm=None\n",
    "      def build(self,imshape):\n",
    "          self.inp_size=imshape\n",
    "          self.batch_norm=tf.keras.layers.BatchNormalization()\n",
    "          self.conv_layer=tf.keras.layers.Conv2D(filters=self.inp_size[-1]//2,kernel_size=3,padding='same',activation='relu',kernel_initializer=tf.keras.initializers.GlorotNormal(seed=12),use_bias=False)\n",
    "          self.upsample_layer=tf.keras.layers.UpSampling2D(size=(2,2),interpolation='bilinear',data_format='channels_last',)\n",
    "      def call(self,X):\n",
    "      \n",
    "          x1=self.upsample_layer(X)\n",
    "          x1=self.conv_layer(x1)\n",
    "          x1=self.batch_norm(x1)\n",
    "          x1=tf.keras.activations.relu(x1)\n",
    "          return x1\n",
    "\n",
    "\n",
    "    # Preparing Text Detection Model\n",
    "    # we have used RESNET50 pretrained on imagenet dataset for Shared Convolutions\n",
    "    resnet=tf.keras.applications.ResNet50(input_shape=(512,512,3),include_top=False,weights='imagenet')\n",
    "    tf.keras.backend.clear_session()\n",
    "    layers=resnet.layers\n",
    "    x1,x2,x3,x4=None,None,None,None\n",
    "    for i in range(len(layers)): \n",
    "      x=layers[i]\n",
    "      if x.name=='pool1_pool':\n",
    "          x1=x\n",
    "      if x.name=='conv3_block1_1_conv':\n",
    "          x2=x\n",
    "      if x.name=='conv4_block1_1_conv':\n",
    "          x3=x   \n",
    "      if x.name=='conv5_block3_2_conv':\n",
    "          x4=x  \n",
    "    #  input_1 ,conv1_relu\n",
    "    m=x4.output\n",
    "    m=Deconv_layer('deconv1')(m)\n",
    "    m=tf.keras.layers.add([m,x3.output])\n",
    "\n",
    "    m=Deconv_layer('deconv2')(m)\n",
    "    m=tf.keras.layers.add([m,x2.output])\n",
    "\n",
    "    m=Deconv_layer('deconv3')(m)\n",
    "    m=tf.keras.layers.add([m,x1.output])\n",
    "    m=tf.keras.layers.BatchNormalization()(m)\n",
    "    m=Deconv_layer('deconv4')(m)\n",
    "    m=Deconv_layer('deconv5')(m)\n",
    "    score=tf.keras.layers.Conv2D(1,kernel_size=3,padding='same',activation='sigmoid')(m)\n",
    "\n",
    "    # Used this beacause sigmoid gives values in range of 0-1(as mentioned in git repository)\n",
    "    geo_map=tf.keras.layers.Conv2D(4,kernel_size=3,padding='same',activation='sigmoid')(m)*512\n",
    "    # Angles are assumed to be between [-45 to 45]\n",
    "    angle_map=(tf.keras.layers.Conv2D(1,kernel_size=3,padding='same',activation='sigmoid')(m)-0.5)*np.pi/2\n",
    "    out=tf.concat([score,geo_map,angle_map],axis=3)\n",
    "    detection_model=tf.keras.Model(resnet.input,out,name='detector')\n",
    "\n",
    "    for layers in resnet.layers:\n",
    "        layers.trainable=False  \n",
    "\n",
    "    #Loading the saved weights of detection model\n",
    "    detection_model.load_weights('/content/drive/MyDrive/detector_icdar50.h5')\n",
    "    return detection_model\n",
    "      \n",
    "\n",
    "@streamlit.cache(show_spinner=False)\n",
    "def recognition():\n",
    "    #Text Recognition Model\n",
    "    inputs = tf.keras.layers.Input(name='the_input', shape=(64,128,3), dtype='float32')  \n",
    "\n",
    "    inner = tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(inputs) \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max1')(inner)\n",
    "\n",
    "    inner = tf.keras.layers.Dropout(0.2)(inner)\n",
    "\n",
    "    inner = tf.keras.layers.Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)  \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max2')(inner)\n",
    "\n",
    "    inner = tf.keras.layers.Dropout(0.2)(inner)\n",
    "\n",
    "    inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)  \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv4', kernel_initializer='he_normal')(inner)  \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max3')(inner)  \n",
    "\n",
    "    inner = tf.keras.layers.Dropout(0.2)(inner)\n",
    "\n",
    "    inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv5', kernel_initializer='he_normal')(inner)  \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.Conv2D(32, (3, 3), padding='same', name='conv6')(inner)   \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.MaxPooling2D(pool_size=(2, 1), name='max4')(inner)  \n",
    "\n",
    "    inner = tf.keras.layers.Dropout(0.2)(inner)\n",
    "\n",
    "    inner = tf.keras.layers.Conv2D(64, (3, 3), padding='same', kernel_initializer='he_normal', name='con7')(inner) \n",
    "    inner = tf.keras.layers.BatchNormalization()(inner)\n",
    "    inner = tf.keras.layers.Activation('relu')(inner)\n",
    "    inner = tf.keras.layers.Reshape(target_shape=((64,512)), name='reshape')(inner)  \n",
    "    inner = tf.keras.layers.Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner) \n",
    "\n",
    "    out=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(32,return_sequences=True,go_backwards=True))(inner)\n",
    "    out=tf.keras.layers.Bidirectional(tf.keras.layers.GRU(128,return_sequences=True,go_backwards=True))(out)\n",
    "    x=tf.keras.layers.Dense(100)(out)#Here we hve given 100 because vocab size is 99 and 1 extra is for blank symbol\n",
    "    x=tf.keras.activations.softmax(x)\n",
    "    recognition_model=tf.keras.models.Model(inputs,x)\n",
    "\n",
    "    # Save the weights\n",
    "    recognition_model.load_weights('/content/drive/MyDrive/recoginzer1.h5')\n",
    "    return recognition_model\n",
    "\n",
    "detection_model = detection()\n",
    "recognition_model = recognition()\n",
    "\n",
    "#Preparing vocabulary for Text Recognition Branch\n",
    "CHAR_VECTOR = \" 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ-~`<>'.:;^/|!?$%#@&*()[]{}_+=,\\\\\\\"\"\n",
    "NUM_CLASSES = len(CHAR_VECTOR) \n",
    "char_index={}\n",
    "index_char={}\n",
    "for i,val in enumerate(CHAR_VECTOR):\n",
    "  index_char[i+1]=val\n",
    "  char_index[val]=i+1\n",
    "\n",
    "\n",
    "streamlit.title('FOTS:TEXT Detection and Recognition')\n",
    "streamlit.header('Enter the image')\n",
    "streamlit.text('Upload an image and model with detect the tect in the image and recognize what is written in text')\n",
    "img=streamlit.file_uploader('upload a image')\n",
    "if img:    \n",
    "  streamlit.image(img,width=512)\n",
    "  image = Image.open(img)\n",
    "  img = np.array(image)\n",
    "  im,txt=Final_Model(img)\n",
    "  txt=','.join(txt)\n",
    "  im=cv2.resize(im,(512,400))\n",
    "  streamlit.header('Image after Model Detected the text and Recognized the Text')\n",
    "  streamlit.image(im,caption=txt)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "oak04LqcgujI",
    "outputId": "ec25eff1-bbdc-4941-cf7f-0812d6a00efe"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'http://6d08723dcb0c.ngrok.io'"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!streamlit run app.py &>/dev/null&\n",
    "public_url = ngrok.connect(port='8501')\n",
    "public_url"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deployment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
